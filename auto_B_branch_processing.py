# @ File(label='Choose a directory with datasets', style='directory') datasets_dir
# @ File(label='Choose a file with metadata about embryo directions', style='file') metadata_file
# @ String(label='Dataset prefix', value='MGolden2022A-') dataset_name_prefix


# Written by Artemiy Golden on Jan 2022 at AK Stelzer Group at Goethe Universitaet Frankfurt am Main

import os
import fnmatch
import json
import logging
from datetime import datetime

from numpy import safe_eval
from java.io import File
from ij.io import FileSaver
from ij.io import OpenDialog
from ij import IJ, ImagePlus
from ij.plugin.filter import RankFilters  
from fiji.threshold import Auto_Threshold
from ij.plugin.filter import ParticleAnalyzer 
from ij.measure import ResultsTable
from ij.measure import Measurements
from ij.plugin.frame import RoiManager
from ij.process import ImageProcessor
from fiji.selection import Select_Bounding_Box
from ij.plugin import RoiRotator

EXAMPLE_JSON_METADATA_FILE = """
Example JSON metadata file contents:
{
	"datasets": [
		{
			"ID": 1,
			"specimens_for_directions_1234": [
				5,
				6,
				4,
				7
			]
		},
		{
			"ID": 3,
			"specimens_for_directions_1234": [
				0,
				1,
				2,
				3
			]
		}
	]
}"""


def process_datasets(datasets_dir, metadata_file, dataset_name_prefix):
	# Converting a File object to a string.
	if isinstance(metadata_file, File):
		metadata_file = metadata_file.getAbsolutePath()
	if isinstance(datasets_dir, File):
		datasets_dir = datasets_dir.getAbsolutePath()

	with open(metadata_file) as f:
		try:
			datasets_meta = json.load(f)
		except ValueError as err:
			print("Could not load the JSON metadata file.")
			print("Error generated by the JSON parser: \n%s" % err)
			print(EXAMPLE_JSON_METADATA_FILE)
			exit(1)

	now = datetime.now()
	dt_string = now.strftime("%Y-%b-%d-%H%M%S")
	logging.basicConfig(filename=os.path.join(datasets_dir, "%s-sort_rename.log" % dt_string),
						filemode='w',
						format='%(asctime)s-%(levelname)s - %(message)s',
						datefmt='%d-%b-%y %H:%M:%S',
						level=logging.INFO)

	for dataset in datasets_meta["datasets"]:
		dataset_id = dataset["ID"]
		specimens = dataset["specimens_for_directions_1234"]

		if not is_dataset_ID_input_valid(dataset_id):
			print("Error while parsing .json file: not a valid dataset ID: \"%s\" skipping. Dataset ID should be an integer from 0 to 9999." % dataset_id)
			print(EXAMPLE_JSON_METADATA_FILE)
			continue
		if not is_specimen_input_valid(specimens):
			print("Error while parsing .json file: not a valid specimen list \"%s\" for the dataset with ID: \"%s\" skipping." % (
				specimens, dataset_id))
			print(EXAMPLE_JSON_METADATA_FILE)
			continue

		raw_images_dir = get_raw_images_dir(datasets_dir, dataset_id)
		if not raw_images_dir:
			continue
		move_files(
			raw_images_dir, specimens, dataset_id, dataset_name_prefix)
		print("Arranged files for the dataset: DS%04d" % dataset_id)
		crop_dataset(dataset, raw_images_dir)


def get_raw_images_dir(datasets_dir, dataset_id):
	dirs = [name for name in os.listdir(
		datasets_dir) if os.path.isdir(os.path.join(datasets_dir, name))]

	this_dataset_dir = fnmatch.filter(dirs, "DS%04d*" % dataset_id)
	if len(this_dataset_dir) > 1:
		print("Error: there are multiple directories for the dataset with ID: %04d. Skipping it." % dataset_id)
		return None
	if len(this_dataset_dir) == 0:
		print("Error: there are no directories for the dataset with ID: %04d. Skipping it." % dataset_id)
		return None
	raw_images_dir = os.path.join(
		datasets_dir, this_dataset_dir[0], "(P0)-ZStacks-Raw")
	if not os.path.isdir(raw_images_dir):
		print("Error: there are no (P0)-ZStacks-Raw directoriy for the dataset with ID: %04d. Skipping it." % dataset_id)
		return None
	return raw_images_dir


def move_files(raw_images_dir, specimens_per_direction, dataset_id, dataset_name_prefix):
	direction_dirs = []
	for i in range(1, 5):
		new_dir = os.path.join(raw_images_dir, "DR" + str(i).zfill(4))
		direction_dirs.append(new_dir)
		if not os.path.exists(new_dir):
			os.mkdir(new_dir)

	for file_name in os.listdir(raw_images_dir):
		file_path = os.path.join(raw_images_dir, file_name)

		if os.path.isdir(file_path):
			continue
		if not file_name.endswith((".tif", ".TIF")):
			continue

		specimen = int(
			file_name[file_name.find("SPC0") + 4: file_name.find("SPC0") + 6])

		if not specimen in specimens_per_direction:
			raise Exception("In the metadata for the dataset: DS %04d there is no entry for the specimen: %i" % (
				dataset_id, specimen))

		embryo_direction = specimens_per_direction.index(specimen) + 1
		time_point = int(
			file_name[file_name.find("TL") + 2: file_name.find("TL") + 6]) + 1
		new_file_name = "%sDS%04dTP%04dDR%04dCH0001PL(ZS).tif" % (dataset_name_prefix,
																  dataset_id,
																  time_point,
																  embryo_direction)
		os.rename(file_path, os.path.join(
			direction_dirs[embryo_direction - 1], new_file_name))
		logging.info("New file \n%s\n Full path:\n%s\n Original name: \n%s\n Original path: \n%s\n" % (new_file_name,
																									   os.path.join(
																										   direction_dirs[embryo_direction - 1], new_file_name),
																									   file_name,
																									   file_path)
					 )


def is_specimen_input_valid(specimens_per_direction):
	if not isinstance(specimens_per_direction, list):
		return False
	if sorted(specimens_per_direction) == [0, 1, 2, 3] or sorted(specimens_per_direction) == [4, 5, 6, 7]:
		return True
	return False


def is_dataset_ID_input_valid(dataset_id):
	if not isinstance(dataset_id, int):
		return False
	if dataset_id in range(10000):
		return True
	return False


def crop_dataset(dataset_meta, raw_images_dir):
	for direction in  # dataset_meta[directions]:
		raw_images_direction_dir = raw_images_dir+direction
		max_projections_dir =  # (B3)-TStacks-ZM in root dataset dir + direction dir
		cropped_raw_zstacks_dir = #B2
		metadata_dir = #B1 + direction

		if does_crop_finished_file_exist(metadata_dir):
			continue

		max_proj_stack = make_max_projections(raw_images_direction_dir)
		save(max_proj_stack, max_projections_dir+backup_subdir)
		max_time_projection = make_max_time_projection(max_proj_stack)
		crop_template, cropped_max_time_projection = create_crop_template(max_time_projection)
		save(crop_template, metadata_dir)
		save(cropped_max_time_projection, metadata_dir)
		cropped_max_projections_stack = crop_stack_by_template(max_time_projection, crop_template)
		save(cropped_max_projections_stack, max_projections_dir)
		crop_many_stacks(raw_images_direction_dir, cropped_raw_zstacks_dir, crop_template)
		first_raw_cropped_zstack =  # first zstack from cropped_raw_zstacks_dir
		middle_plane = get_embryo_middle_plane(first_raw_cropped_zstack)
		subset_ebryo_planes(middle_plane, cropped_raw_zstacks_dir)


def make_max_projections(raw_images_dir):
	return max_proj_stack

def make_max_time_projection(max_proj_stack):
	return max_time_projection



def create_crop_template(max_time_projection):
	IJ.run("Clear Results")
	file_path = "/home/tema/work/for_Mashunja/test_images/max_time_project_of_max_project.tif"

	imp = IJ.openImage(file_path)
	imp.show()
	ip = imp.getProcessor().duplicate()  # get pixel array?, as a copy


	imp2 = ImagePlus("mask", ip)
	# Remove noise by running a median filter
	# with a radius of 4
	radius = 4
	RankFilters().rank(ip, radius, RankFilters.MEDIAN)

	hist = ip.getHistogram()
	triag_threshold = Auto_Threshold.Triangle(hist)
	ip.setThreshold(triag_threshold, float("inf"), ImageProcessor.NO_LUT_UPDATE)
	#ip.createMask()
	
	IJ.run(imp2, "Convert to Mask", "")
	imp2.show()
	table = ResultsTable()
	roim = RoiManager() # Initialise without display
	MIN_PARTICLE_SIZE = 10000; # pixel ^ 2
	MAX_PARTICLE_SIZE = float("inf")
	ParticleAnalyzer.setRoiManager(roim)
	pa = ParticleAnalyzer(
						 ParticleAnalyzer.ADD_TO_MANAGER,
						 Measurements.ELLIPSE,
						 table,
						 MIN_PARTICLE_SIZE,
						 MAX_PARTICLE_SIZE
						 )
	pa.analyze(imp2)
	rot_angle = round(table.getValue("Angle", 0))
	print rot_angle
	roi_arr = roim.getRoisAsArray()
	imp.setRoi(roi_arr[len(roi_arr) - 1])
	IJ.run(imp, "Select Bounding Box (guess background color)", "")
	bounding_roi = imp.getRoi()
	# print bounding_roi.getRotationCenter().getBounds()
	bounding_center_x = bounding_roi.getContourCentroid()[0]
	bounding_center_y = bounding_roi.getContourCentroid()[1]
	IJ.run(imp, "Specify...", "width=1050 height=600 x=%s y=%s centered" % (bounding_center_x, bounding_center_y))
	bounding_roi = imp.getRoi()
	bounding_roi_rot = RoiRotator.rotate(bounding_roi, -rot_angle)
	imp.setRoi(bounding_roi_rot, True)
	final_imp = imp.crop()
	IJ.run(final_imp, "Select All", "")
	IJ.run(final_imp, "Rotate... ", "angle=%s grid=1 interpolation=Bilinear" % rot_angle)
	final_center_x = final_imp.getWidth() / 2
	final_center_y = final_imp.getHeight() / 2
	print final_center_x
	IJ.run(final_imp, "Specify...", "width=1050 height=600 x=%s y=%s centered" %
		   (final_center_x, final_center_y))
	final_imp = final_imp.crop()
	IJ.run(final_imp, "Rotate 90 Degrees Right", "")
	IJ.run(final_imp, "Flip Horizontally", "")
	final_imp.show()
	return (crop_template, cropped_max_time_proj)


def crop_stack_by_template(stack, template):
	return cropped_stack


if __name__ in ['__builtin__', '__main__']:
	# process_datasets("/home/tema/work/for_Mashunja/fiji_scripts/test_dir/",
	#						 "/home/tema/work/for_Mashunja/fiji_scripts/directions.json",
	#						 dataset_name_prefix="MGolden2022A-")
	process_datasets(datasets_dir, metadata_file, dataset_name_prefix)
