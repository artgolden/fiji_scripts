# @ File(label='Choose a directory with datasets', style='directory') datasets_dir
# @ File(label='Choose a file with metadata about embryo directions', style='file') metadata_file
# @ String(label='Dataset prefix', value='MGolden2022A-') dataset_name_prefix

# Written by Artemiy Golden on Jan 2022 at AK Stelzer Group at Goethe Universitaet Frankfurt am Main
# Last manual update of this line 2022.2.16 :) 

import os
import re
import fnmatch
import json
import logging
from datetime import datetime

from java.io import File
from ij.io import FileSaver
from ij import IJ, ImagePlus, ImageStack
from ij.plugin.filter import RankFilters  
from fiji.threshold import Auto_Threshold
from ij.plugin.filter import ParticleAnalyzer 
from ij.measure import ResultsTable
from ij.measure import Measurements
from ij.plugin.frame import RoiManager
from ij.process import ImageProcessor
from ij.plugin import RoiRotator
from ij.plugin import ZProjector
from ij.plugin import Slicer


EXAMPLE_JSON_METADATA_FILE = """
Example JSON metadata file contents:
{
	"datasets": [
		{
			"ID": 1,
			"specimens_for_directions_1234": [
				5,
				6,
				4,
				7
			]
		},
		{
			"ID": 3,
			"specimens_for_directions_1234": [
				0,
				1,
				2,
				3
			]
		}
	]
}"""

METADATA_DIR_NAME = "(B1)-Metadata"
TSTACKS_DIR_NAME = "(B3)-TStacks-ZM"
RAW_IMAGES_DIR_NAME = "(P0)-ZStacks-Raw"
RAW_CROPPED_DIR_NAME = "(B2)-ZStacks"

class FredericFile:
	"""
	File naming for light-sheet image files. Frederic Stroblâ„¢ 
	Example file name: MGolden2022A-DS0001TP0001DR0001CH0001PL(ZS).tif
	:param file_name: full image file name
	:type file_name: str
	"""
	dataset_name = ""
	dataset_id = 0
	time_point = ""
	direction = ""
	channel = ""
	plane = ""
	extension = ""

	def __init__(self, file_name):
		name_parts = re.split("-DS|TP|DR|CH|PL|\.", file_name)
		if len(name_parts) != 7:
			raise Exception("Image file name is improperly formatted! Check documentation inside the script.")
		self.dataset_name, self.dataset_id, self.time_point, self.direction, self.channel, self.plane, self.extension = name_parts
		self.extension.lower()

	def get_name(self):
		return "%s-DS%sTP%sDR%sCH%sPL%s.%s" % (self.dataset_name, 
											   self.dataset_id, 
											   self.time_point, 
											   self.direction, 
											   self.channel, 
											   self.plane, 
											   self.extension)

		



def process_datasets(datasets_dir, metadata_file, dataset_name_prefix):
	"""Main function for processing the datasets.

	Args:
		datasets_dir (java.io.File): directory with subdirectories for each dataset	(input from the user)
		metadata_file (java.io.File): JSON file with metadata for each dataset (input from the user)
		dataset_name_prefix (str): Prefix that will be added to all image files for all datasets (input from the user)
	"""
	# Converting a Java File object to a string.
	if isinstance(metadata_file, File):
		metadata_file = metadata_file.getAbsolutePath()
	if isinstance(datasets_dir, File):
		datasets_dir = datasets_dir.getAbsolutePath()

	with open(metadata_file) as f:
		try:
			datasets_meta = json.load(f)
		except ValueError as err:
			print("Could not load the JSON metadata file.")
			print("Error generated by the JSON parser: \n%s" % err)
			print(EXAMPLE_JSON_METADATA_FILE)
			exit(1)

	now = datetime.now()
	dt_string = now.strftime("%Y-%b-%d-%H%M%S")
	logging.basicConfig(filename=os.path.join(datasets_dir, "%s-sort_rename.log" % dt_string),
						filemode='w',
						format='%(asctime)s-%(levelname)s - %(message)s',
						datefmt='%d-%b-%y %H:%M:%S',
						level=logging.INFO)

	for dataset in datasets_meta["datasets"]:
		dataset_id = dataset["ID"]
		specimens = dataset["specimens_for_directions_1234"]

		if not is_dataset_ID_input_valid(dataset_id):
			print("Error while parsing .json file: not a valid dataset ID: \"%s\" skipping. Dataset ID should be an integer from 0 to 9999." % dataset_id)
			print(EXAMPLE_JSON_METADATA_FILE)
			continue
		if not is_specimen_input_valid(specimens):
			print("Error while parsing .json file: not a valid specimen list \"%s\" for the dataset with ID: \"%s\" skipping." % (
				specimens, dataset_id))
			print(EXAMPLE_JSON_METADATA_FILE)
			continue

		raw_images_dir = get_raw_images_dir(datasets_dir, dataset_id)
		if not raw_images_dir:
			continue
		move_files(
			raw_images_dir, specimens, dataset_id, dataset_name_prefix)
		print("Arranged files for the dataset: DS%04d" % dataset_id)

		raw_images_direction_dirs = make_directions_dirs(raw_images_dir)
		root_dataset_dir = os.path.split(raw_images_dir)[0]
		meta_dir = os.path.join(root_dataset_dir, METADATA_DIR_NAME)
		meta_d_dirs = make_directions_dirs(meta_dir)
		tstack_dataset_dirs = make_directions_dirs(
		os.path.join(root_dataset_dir, TSTACKS_DIR_NAME))
		raw_cropped_dirs = make_directions_dirs(
                    os.path.join(root_dataset_dir, RAW_CROPPED_DIR_NAME))
		for raw_dir, tstack_dir, m_dir, raw_cropped_dir in zip(raw_images_direction_dirs, tstack_dataset_dirs, meta_d_dirs, raw_cropped_dirs):
			backup_dir = os.path.join(tstack_dir, "uncropped_backup")
			if not os.path.exists(backup_dir):
				os.mkdir(backup_dir)
			max_proj_stack = make_max_Z_projections_for_folder(
				raw_dir, os.path.join(tstack_dir, "uncropped_backup"))

			max_time_proj = project_a_stack(max_proj_stack)
			max_time_proj_file_name = get_tiff_name_from_dir(
				os.path.join(tstack_dir, "uncropped_backup"))
			max_time_proj_file_name.time_point = "(TM)"
			logging.info("Created max time projection\n" + os.path.join(m_dir, max_time_proj_file_name.get_name()))
			fs = FileSaver(max_time_proj)
			fs.saveAsTiff(os.path.join(m_dir, max_time_proj_file_name.get_name()))

			crop_template, cropped_max_time_proj = create_crop_template(max_time_proj, m_dir, dataset)
			fs = FileSaver(cropped_max_time_proj)
			fs.saveAsTiff(os.path.join(
				m_dir, "cropped_max_time_proj.tif"))

			cropped_tstack_file_name = get_tiff_name_from_dir(
				raw_dir)
			cropped_tstack_file_name.time_point = "(TS)"
			cropped_tstack_file_name.plane = "(ZM)"
			cropped_tstack = crop_stack_by_template(max_proj_stack, crop_template, dataset)
			fs = FileSaver(cropped_tstack)
			fs.saveAsTiff(os.path.join(tstack_dir, cropped_tstack_file_name.get_name()))

			planes_kept = (0, 0)
			for i, raw_stack_file_name in enumerate(get_tiffs_in_directory(raw_dir)):
				raw_stack = IJ.openImage(raw_stack_file_name)
				IJ.run(raw_stack, "Properties...",
				       "frames=1 pixel_width=1.0000 pixel_height=1.0000 voxel_depth=4.0000")
				raw_stack_cropped = crop_stack_by_template(raw_stack, crop_template, dataset)
				if i == 0:
					planes_kept = find_planes_to_keep(raw_stack_cropped)
				# Cleare all of the metadata
				raw_stack_cropped = reset_img_properties(raw_stack_cropped)
				raw_stack_cropped = subset_planes(raw_stack_cropped, planes_kept)
				fs = FileSaver(raw_stack_cropped)
				fs.saveAsTiff(os.path.join(raw_cropped_dir, os.path.split(raw_stack_file_name)[1]))


def get_raw_images_dir(datasets_dir, dataset_id):
	dirs = [name for name in os.listdir(
		datasets_dir) if os.path.isdir(os.path.join(datasets_dir, name))]

	this_dataset_dir = fnmatch.filter(dirs, "DS%04d*" % dataset_id)
	if len(this_dataset_dir) > 1:
		print("Error: there are multiple directories for the dataset with ID: %04d. Skipping it." % dataset_id)
		return None
	if len(this_dataset_dir) == 0:
		print("Error: there are no directories for the dataset with ID: %04d. Skipping it." % dataset_id)
		return None
	raw_images_dir = os.path.join(
		datasets_dir, this_dataset_dir[0], RAW_IMAGES_DIR_NAME)
	if not os.path.isdir(raw_images_dir):
		print("Error: there are no %s directoriy for the dataset with ID: %04d. Skipping it." %
		      (RAW_IMAGES_DIR_NAME, dataset_id))
		return None
	return raw_images_dir


def make_directions_dirs(input_dir):
	direction_dirs = []
	for i in range(1, 5):
			new_dir = os.path.join(input_dir, "DR" + str(i).zfill(4))
			direction_dirs.append(new_dir)
			if not os.path.exists(new_dir):
				os.mkdir(new_dir)
	return direction_dirs
		

def get_tiff_name_from_dir(input_dir):
	file_name = None
	for fname in os.listdir(input_dir):
		if fname.lower().endswith(".tif"):
			file_name = fname
		break
	if file_name == None:
		raise Exception("Did not find any TIFF files in a directory.")

	file_name = FredericFile(file_name)
	return file_name


def move_files(raw_images_dir, specimens_per_direction, dataset_id, dataset_name_prefix):
	"""Splits the embryo images by direction and puts in separate direction folders. 
	Renames the files to conform to FredericFile format.

	Args:
		raw_images_dir (str): full path to mixed raw images files
		specimens_per_direction (int[]): list of correspondance between specimen number and the direction of the ebryo in this specimen. 
		Directions are indexes in the speciments_per_direction list + 1
		dataset_id (int): ID number of the dataset
		dataset_name_prefix (str): prefix that the user specifies for the dataset

	Raises:
		Exception: metadata does not contain the specimen extracted from the file names
	"""
	direction_dirs = make_directions_dirs(raw_images_dir)

	for file_name in os.listdir(raw_images_dir):
		file_path = os.path.join(raw_images_dir, file_name)

		if os.path.isdir(file_path):
			continue
		if not file_name.endswith((".tif", ".TIF")):
			continue

		specimen = int(
			file_name[file_name.find("SPC0") + 4: file_name.find("SPC0") + 6])

		if not specimen in specimens_per_direction:
			raise Exception("In the metadata for the dataset: DS %04d there is no entry for the specimen: %i" % (
				dataset_id, specimen))

		embryo_direction = specimens_per_direction.index(specimen) + 1
		time_point = int(
			file_name[file_name.find("TL") + 2: file_name.find("TL") + 6]) + 1
		new_file_name = "%sDS%04dTP%04dDR%04dCH0001PL(ZS).tif" % (dataset_name_prefix,
																  dataset_id,
																  time_point,
																  embryo_direction)
		os.rename(file_path, os.path.join(
			direction_dirs[embryo_direction - 1], new_file_name))
		logging.info("New file \n%s\n Full path:\n%s\n Original name: \n%s\n Original path: \n%s\n" % (new_file_name,
																									   os.path.join(
																										   direction_dirs[embryo_direction - 1], new_file_name),
																									   file_name,
																									   file_path)
					 )


def is_specimen_input_valid(specimens_per_direction):
	if not isinstance(specimens_per_direction, list):
		return False
	if sorted(specimens_per_direction) == [0, 1, 2, 3] or sorted(specimens_per_direction) == [4, 5, 6, 7]:
		return True
	return False


def is_dataset_ID_input_valid(dataset_id):
	if not isinstance(dataset_id, int):
		return False
	if dataset_id in range(10000):
		return True
	return False


def get_tiffs_in_directory(directory):
	"""Get all TIFF file paths in a directory. Subdirectories are not searched.

	Args:
		directory (str): full path to directory

	Raises:
		Exception: If no images were found

	Returns:
		str[]: list of full paths to tiff files
	"""
	file_names = []
	for fname in os.listdir(directory):
		if fname.lower().endswith(".tif"):
			file_names.append(os.path.join(directory, fname))
	file_names = sorted(file_names)
	if len(file_names) < 1:
		raise Exception("No image files found in %s" % directory)	
	return file_names


def project_a_stack(stack):
	"""Project a stack of images along the Z axis 

	Args:
		stack ImagePlus: stack of images to project

	Returns:
		ImagePlus: max-projection
	"""
	zp = ZProjector(stack)
	zp.setMethod(ZProjector.MAX_METHOD)
	zp.doProjection()
	zpimp = zp.getProjection()
	return zpimp


def make_max_Z_projections_for_folder(input_dir, output_dir):
	"""Takes all stacks from a directory, does their max-projection, makes a stack of max-projections, saves it to output directory and returns it. 

	Args:
		input_dir (string): path to stacks of images (has to be images from ImagePlus objects)
		output_dir (string): path to output folder

	Returns:
		ImagePlus: stack of max-projections
	"""
	fnames = get_tiffs_in_directory(input_dir)
	# Open and stack images
	img_for_dims = IJ.openImage(fnames[0])
	stack_list = []
	for fname in fnames:
		stack = IJ.openImage(fname)
		# Select which dimension to project
		max_proj = project_a_stack(stack)
		stack_list.append(max_proj.getProcessor())
	tstack_name = FredericFile(os.path.split(fnames[0])[1])
	tstack_name.time_point = "(TS)"
	tstack_name.plane = "(ZM)"
	max_proj_stack = ImageStack(img_for_dims.width, img_for_dims.height)
	for slice in stack_list:
		max_proj_stack.addSlice(None, slice)
	max_proj_stack = ImagePlus("max_proj", max_proj_stack)
	fs = FileSaver(max_proj_stack)
	fs.saveAsTiff( os.path.join(output_dir, tstack_name.get_name()))
	return max_proj_stack


def create_crop_template(max_time_projection, meta_dir, dataset):
	"""Crop max_time_projection, create crop template .roi object, save it in meta_dir.

	Args:
		max_time_projection (ImagePlus): a single image of max projection of a time stack of max projections
		meta_dir (str): full path to metadata dir
		dataset (dict): metadata about the dataset to extract information about embryo orientation

	Returns:
		crop_template (Roi): bounding box around the embryo with proper rotation and size
		cropped_max_time_proj (ImagePlus): cropped max time projection
	"""
	IJ.run("Clear Results")
	#TODO:
	# - Rotate an image based on a parameter in JSON file 
	# - Create switching of different size bounding boxes based on embryo size
	imp = max_time_projection
	ip = imp.getProcessor().duplicate()  # get pixel array?, as a copy

	imp2 = ImagePlus("mask", ip)
	radius = 4
	RankFilters().rank(ip, radius, RankFilters.MEDIAN)

	hist = ip.getHistogram()
	triag_threshold = Auto_Threshold.Triangle(hist)
	ip.setThreshold(triag_threshold, float("inf"), ImageProcessor.NO_LUT_UPDATE)
	IJ.run(imp2, "Convert to Mask", "")
	table = ResultsTable()
	roim = RoiManager(False)  # Initialise without display (boolean value is ignored)
	MIN_PARTICLE_SIZE = 10000  # pixel ^ 2
	MAX_PARTICLE_SIZE = float("inf")
	ParticleAnalyzer.setRoiManager(roim)
	pa = ParticleAnalyzer(
            ParticleAnalyzer.ADD_TO_MANAGER,
            Measurements.ELLIPSE,
            table,
            MIN_PARTICLE_SIZE,
            MAX_PARTICLE_SIZE
        )
	pa.analyze(imp2)
	rot_angle = round(table.getValue("Angle", 0))
	roi_arr = roim.getRoisAsArray()
	roim.runCommand('reset')
	imp.setRoi(roi_arr[len(roi_arr) - 1])
	IJ.run(imp, "Select Bounding Box (guess background color)", "")
	bounding_roi = imp.getRoi()
	bounding_center_x = bounding_roi.getContourCentroid()[0]
	bounding_center_y = bounding_roi.getContourCentroid()[1]
	IJ.run(imp, "Specify...", "width=1050 height=600 x=%s y=%s centered" %
	       (bounding_center_x, bounding_center_y))
	roim.runCommand('reset')
	bounding_roi = imp.getRoi()
	bounding_roi_rot = RoiRotator.rotate(bounding_roi, -rot_angle)
	imp.setRoi(bounding_roi_rot, True)
	crop_template = imp.getRoi()
	roim.addRoi(crop_template)
	roim.select(0)
	roim.runCommand("Save", os.path.join(meta_dir, "crop_template.roi"))
	final_imp = imp.crop() # This crops by a unrotated bounding box created around the rotated selection box
						   # so later, when we rotate and crop again there will be no blacked corners in the image.
	IJ.run(final_imp, "Select All", "")
	IJ.run(final_imp, "Rotate... ",
	       "angle=%s grid=1 interpolation=Bilinear" % rot_angle)
	final_center_x = final_imp.getWidth() / 2
	final_center_y = final_imp.getHeight() / 2
	IJ.run(final_imp, "Specify...", "width=1050 height=600 x=%s y=%s centered" %
            (final_center_x, final_center_y))
	cropped_max_time_proj = final_imp.crop()
	IJ.run(cropped_max_time_proj, "Rotate 90 Degrees Right", "")
	IJ.run(cropped_max_time_proj, "Flip Horizontally", "")
	roim.close()
	table.reset()
	return (crop_template, cropped_max_time_proj)


def get_polygon_roi_angle(roi):
	"""Returns an angle between first line in the PolygonRoi and horizontal line

	Args:
		roi (PolygonRoi): intended for rectangular Rois

	Returns:
		double: angle between first line in the PolygonRoi and horizontal line
	"""
	x1 = roi.getPolygon().xpoints[0]
	x2 = roi.getPolygon().xpoints[1]
	y1 = roi.getPolygon().ypoints[0]
	y2 = roi.getPolygon().ypoints[1]
	angle = roi.getAngle(x1, y1, x2, y2)
	return angle


def crop_stack_by_template(stack, crop_template, dataset):
	"""Crop stack by provided PolygonRoi which should be a rotated rectangle around the embryo.
	It also flips the ebryo accroding to metadata about embryo facing direction, so that illumination is from the left.

	Args:
		stack (ImagePlus): a stack of image planes
		crop_template (PolygonRoi): rotated bounding rectangle around the embryo
		dataset (dict): metadata about the dataset to extract information about embryo orientation

	Returns:
		ImagePlus: cropped stack
	"""

	stack.setRoi(crop_template)
	cropped_stack = stack.crop("stack")
	stack = None
	# cropped_stack.show()
	IJ.run(cropped_stack, "Select All", "")

	IJ.run(cropped_stack, "Rotate... ",
		"angle=%s grid=1 interpolation=Bilinear stack" % int(round(get_polygon_roi_angle(crop_template))))
	final_center_x = cropped_stack.getWidth() / 2
	final_center_y = cropped_stack.getHeight() / 2
	IJ.run(cropped_stack, "Specify...", "width=1050 height=600 x=%s y=%s centered" %
	       (final_center_x, final_center_y))
	cropped_stack_resized = cropped_stack.crop("stack")
	IJ.run(cropped_stack_resized, "Rotate 90 Degrees Right", "")
	IJ.run(cropped_stack_resized, "Flip Horizontally", "stack")
	return cropped_stack_resized


def find_planes_to_keep(zstack):
	"""Calculates planes to keep, so that the embryo is centered in them.

	Args:
		zstack (ImagePlus): cropped Z-stack

	Returns:
		(int, int): (start_plane, stop_plane) ends have to be included.
	"""
	IJ.run(zstack, "Properties...",
            "pixel_width=1.0000 pixel_height=1.0000 voxel_depth=4.0000")

	# This does not recalculate the pixel values and does not expand the image.
	# So later, when we convert to mask, the image will be number_of_planes in height, and not 4*number_of_planes
	# as would be with the Reslice made from GUI.
	zstack = Slicer.reslice(Slicer(), zstack)

	max_proj_reslice = project_a_stack(zstack)
	ip = max_proj_reslice.getProcessor()
	radius = 4
	RankFilters().rank(ip, radius, RankFilters.MEDIAN)

	hist = ip.getHistogram()
	triag_threshold = Auto_Threshold.Mean(hist)
	ip.setThreshold(triag_threshold, float("inf"), ImageProcessor.NO_LUT_UPDATE)
	IJ.run(max_proj_reslice, "Convert to Mask", "")

	table = ResultsTable()
	# Initialise RoiManager without display (boolean value is ignored)
	roim = RoiManager(False)
	MIN_PARTICLE_SIZE = 2000  # pixel ^ 2
	MAX_PARTICLE_SIZE = float("inf")
	ParticleAnalyzer.setRoiManager(roim)
	pa = ParticleAnalyzer(
            ParticleAnalyzer.ADD_TO_MANAGER,
            Measurements.RECT,
            table,
            MIN_PARTICLE_SIZE,
            MAX_PARTICLE_SIZE
        )
	pa.analyze(max_proj_reslice)
	box_start = table.getValue("BY", 0)
	box_width = table.getValue("Height", 0)
	middle_y = box_start + box_width / 2
	start_plane = int(round(middle_y - 75))
	end_plane = int(round(middle_y + 74))
	return (start_plane, end_plane)
	

def reset_img_properties(image):
	"""Reset properties for an ImagePlus image and remove slice lables

	Args:
		image (ImagePlus): input image

	Returns:
		ImagePlus: image with reset properties
	"""
	depth = 4
	nslices = image.getNSlices()
	if nslices == 1:
		depth = 1
	IJ.run(image, "Properties...", "channels=1 slices=%s frames=1 unit=pixel pixel_width=1.0000 pixel_height=1.0000 voxel_depth=%s.0000 origin=0,0,0" % (nslices, depth))

	# Equivalent of "Remove Slice Labels" I had to do it manually because
	# "Remove Slice Labels" function always displays the image
	stack = image.getStack()
	size = image.getStackSize()
	for i in range(1, size + 1):
		stack.setSliceLabel(None, i)
	if size == 1:
		image.setProperty("Label", None)

	return image


def subset_planes(stack_img, planes):
	"""Leave only specified planes in zstack

	Args:
		zstack (ImagePlus): stack to crop
		planes (int, int): (start_plane, end_plane) ends included in the output stack

	Returns:
		ImagePlus: cropped stack
	"""
	# I had to do it manually because the built in function (Keep slices) always displays the image
	stack = stack_img.getStack()
	cropped_stack = ImageStack(stack.getWidth(), stack.getHeight())
	for i in range(planes[0], planes[1] + 1):
		ip = stack.getProcessor(i)
		cropped_stack.addSlice(ip)
	stack_img.setStack(cropped_stack)
	return stack_img

if __name__ in ['__builtin__', '__main__']:
	process_datasets(datasets_dir, metadata_file, dataset_name_prefix)
