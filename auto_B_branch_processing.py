# @ File(label='Choose a directory with datasets', style='directory') datasets_dir
# @ File(label='Choose a file with metadata about embryo directions', style='file') metadata_file
# @ String(label='Dataset prefix', value='MGolden2022A-') dataset_name_prefix

# Written by Artemiy Golden on Jan 2022 at AK Stelzer Group at Goethe Universitaet Frankfurt am Main
# Last manual update of this line 2022.2.16 :) 

from distutils.dir_util import mkpath
import os
import re
import fnmatch
import json
import logging
from datetime import datetime

from java.io import File
from ij.io import FileSaver
from ij import IJ, ImagePlus, ImageStack, WindowManager
from ij.plugin.filter import RankFilters  
from fiji.threshold import Auto_Threshold
from ij.plugin.filter import ParticleAnalyzer 
from ij.measure import ResultsTable
from ij.measure import Measurements
from ij.plugin.frame import RoiManager
from ij.process import ImageProcessor
from ij.plugin import RoiRotator
from ij.plugin import ZProjector
from ij.plugin import Slicer

#TODO:
# - Create switching of different size bounding boxes based on embryo size



EXAMPLE_JSON_METADATA_FILE = """
Example JSON metadata file contents:
{
    "datasets": [
        {
            "ID": 1,
            "channel_1": {
                "specimens_for_directions_1234": [
                5,
                6,
                4,
                7
                ]                
            },
            "head_direction": "right",
            "use_manual_bounding_box": false
        },
        {
            "ID": 3,
            "channel_1": {
                "specimens_for_directions_1234": [
                    5,
                    6,
                    4,
                    7
                ]
            },
            "channel_2": {
                "specimens_for_directions_1234": [
                    0,
                    2,
                    1,
                    3
                ]
            },
            "head_direction": "left",
            "use_manual_bounding_box": false
        }
    ]
}"""

METADATA_DIR_NAME = "(B1)-Metadata"
TSTACKS_DIR_NAME = "(B3)-TStacks-ZM"
RAW_IMAGES_DIR_NAME = "(P0)-ZStacks-Raw"
RAW_CROPPED_DIR_NAME = "(B2)-ZStacks"

class FredericFile:
	"""
	File naming for light-sheet image files. Frederic Stroblâ„¢ 
	Example file name: MGolden2022A-DS0001TP0001DR0001CH0001PL(ZS).tif
	:param file_name: full image file name
	:type file_name: str
	"""
	dataset_name = ""
	dataset_id = 0
	time_point = ""
	direction = ""
	channel = ""
	plane = ""
	extension = ""

	def __init__(self, file_name):
		name_parts = re.split("-DS|TP|DR|CH|PL|\.", file_name)
		if len(name_parts) != 7:
			raise Exception("Image file name is improperly formatted! Check documentation inside the script.")
		self.dataset_name, self.dataset_id, self.time_point, self.direction, self.channel, self.plane, self.extension = name_parts
		self.extension.lower()

	def get_name(self):
		return "%s-DS%sTP%sDR%sCH%sPL%s.%s" % (self.dataset_name, 
											   self.dataset_id, 
											   self.time_point, 
											   self.direction, 
											   self.channel, 
											   self.plane, 
											   self.extension)

		



def process_datasets(datasets_dir, metadata_file, dataset_name_prefix):
	"""Main function for processing the datasets.

	Args:
		datasets_dir (java.io.File): directory with subdirectories for each dataset	(input from the user)
		metadata_file (java.io.File): JSON file with metadata for each dataset (input from the user)
		dataset_name_prefix (str): Prefix that will be added to all image files for all datasets (input from the user)
	"""
	# Converting a Java File object to a string.
	if isinstance(metadata_file, File):
		metadata_file = metadata_file.getAbsolutePath()
	if isinstance(datasets_dir, File):
		datasets_dir = datasets_dir.getAbsolutePath()

	with open(metadata_file) as f:
		try:
			datasets_meta = json.load(f)
		except ValueError as err:
			print("Could not load the JSON metadata file.")
			print("Error generated by the JSON parser: \n%s" % err)
			print(EXAMPLE_JSON_METADATA_FILE)
			exit(1)

	now = datetime.now()
	dt_string = now.strftime("%Y-%b-%d-%H%M%S")
	logging.basicConfig(filename=os.path.join(datasets_dir, "%s-sort_rename.log" % dt_string),
						filemode='w',
						format='%(asctime)s-%(levelname)s - %(message)s',
						datefmt='%d-%b-%y %H:%M:%S',
						level=logging.INFO)

	# Check metadata file for correctness
	for dataset in datasets_meta["datasets"]:
		if "ID" not in dataset:
			print("Error while parsing .json file. Did not find a dataset ID for one of the datsets. Exiting.")
			exit(1)
		dataset_id = dataset["ID"]
		if "head_direction" not in dataset:
			print("Error while parsing .json file: no head_direction for the dataset with ID: \"%s\". Exiting." % dataset_id)
			print(EXAMPLE_JSON_METADATA_FILE)
			exit(1)
		specimen_directions_in_channels = []
		for chan in range(3):
			channel = "channel_%s" % chan
			if channel in dataset:
				if "specimens_for_directions_1234" not in dataset[channel]:
					print("Error while parsing .json file: no specimens_for_directions_1234 field in channel_%s for the dataset with ID: \"%s\". Exiting." % (channel, dataset_id))
					print(EXAMPLE_JSON_METADATA_FILE)
					exit(1)
				specimen_directions_in_channels.append(
					tuple(dataset[channel]["specimens_for_directions_1234"]))
		specimen_directions_in_channels = tuple(specimen_directions_in_channels)

		if not is_dataset_ID_input_valid(dataset_id):
			print("Error while parsing .json file: not a valid dataset ID: \"%s\". Dataset ID should be an integer from 0 to 9999. Exiting." % dataset_id)
			print(EXAMPLE_JSON_METADATA_FILE)
			exit(1)
		for specimens in specimen_directions_in_channels:
			if not is_specimen_input_valid(specimens):
				print("Error while parsing .json file: not a valid specimen list \"%s\" for the dataset with ID: \"%s\". Exiting." % (
					specimens, dataset_id))
				print(EXAMPLE_JSON_METADATA_FILE)
				exit(1)
		if not dataset["head_direction"] in ["right", "left"]:
			print("Error while parsing .json file: not a valid head_direction \"%s\" for the dataset with ID: \"%s\". Exiting." % (
				dataset["head_direction"], dataset_id))
			print(EXAMPLE_JSON_METADATA_FILE)
			exit(1)
		if specimen_directions_in_channels == ():
			print("Error while parsing .json file: no channels found for the dataset with ID: \"%s\". Exiting." % dataset_id)
			print(EXAMPLE_JSON_METADATA_FILE)
			exit(1)
		raw_images_dir = get_raw_images_dir(datasets_dir, dataset_id)
		if not raw_images_dir:
			print("Exiting.")
			exit(1)
		
			

	for dataset in datasets_meta["datasets"]:
		dataset_id = dataset["ID"]
		specimen_directions_in_channels = []
		for chan in range(3):
			channel = "channel_%s" % chan
			if channel in dataset:
				specimen_directions_in_channels.append(
					tuple(dataset[channel]["specimens_for_directions_1234"]))
		specimen_directions_in_channels = tuple(specimen_directions_in_channels)

		logging.info("Started processing dataset: DS%04d" % dataset_id)
		raw_images_dir = get_raw_images_dir(datasets_dir, dataset_id)
	
		logging.info("	Arranging raw image files")
		try:
			move_files(
				raw_images_dir, specimen_directions_in_channels, dataset_id, dataset_name_prefix)
		except ValueError as e:
			print("Error while moving files for the dataset:\"%s\", skipping the dataset." % dataset_id)
			print(e)
			continue

		for channel, _ in enumerate(specimen_directions_in_channels, start=1):
			chan_dir_name = "CH%04d" % channel
			raw_images_direction_dirs = make_directions_dirs(os.path.join(raw_images_dir, chan_dir_name))
			root_dataset_dir = os.path.split(raw_images_dir)[0]
			meta_dir = os.path.join(root_dataset_dir, METADATA_DIR_NAME)
			meta_d_dirs = make_directions_dirs(os.path.join(meta_dir, chan_dir_name))
			tstack_dataset_dirs = make_directions_dirs(
			os.path.join(root_dataset_dir, TSTACKS_DIR_NAME, chan_dir_name))
			raw_cropped_dirs = make_directions_dirs(os.path.join(root_dataset_dir, RAW_CROPPED_DIR_NAME, chan_dir_name))
			
			for raw_dir, tstack_dir, m_dir, raw_cropped_dir in zip(raw_images_direction_dirs, tstack_dataset_dirs, meta_d_dirs, raw_cropped_dirs):
				backup_dir = os.path.join(tstack_dir, "uncropped_backup")
				if not os.path.exists(backup_dir):
					os.mkdir(backup_dir)
				max_proj_stack = make_max_Z_projections_for_folder(
					raw_dir, os.path.join(tstack_dir, "uncropped_backup"))

				max_time_proj = project_a_stack(max_proj_stack)
				max_time_proj_file_name = get_tiff_name_from_dir(
					os.path.join(tstack_dir, "uncropped_backup"))
				max_time_proj_file_name.time_point = "(TM)"
				logging.info("Created max time projection\n" + os.path.join(m_dir, max_time_proj_file_name.get_name()))
				fs = FileSaver(max_time_proj)
				fs.saveAsTiff(os.path.join(m_dir, max_time_proj_file_name.get_name()))

				crop_template, cropped_max_time_proj = create_crop_template(max_time_proj, m_dir, dataset)
				fs = FileSaver(cropped_max_time_proj)
				fs.saveAsTiff(os.path.join(
					m_dir, "cropped_max_time_proj.tif"))

				cropped_tstack_file_name = get_tiff_name_from_dir(
					raw_dir)
				cropped_tstack_file_name.time_point = "(TS)"
				cropped_tstack_file_name.plane = "(ZM)"
				cropped_tstack = crop_stack_by_template(max_proj_stack, crop_template, dataset)
				fs = FileSaver(cropped_tstack)
				fs.saveAsTiff(os.path.join(tstack_dir, cropped_tstack_file_name.get_name()))

				planes_kept = (0, 0)
				for i, raw_stack_file_name in enumerate(get_tiffs_in_directory(raw_dir)):
					raw_stack = IJ.openImage(raw_stack_file_name)
					IJ.run(raw_stack, "Properties...",
						"frames=1 pixel_width=1.0000 pixel_height=1.0000 voxel_depth=4.0000")
					raw_stack_cropped = crop_stack_by_template(raw_stack, crop_template, dataset)
					if i == 0:
						planes_kept = find_planes_to_keep(raw_stack_cropped, m_dir)
					raw_stack_cropped = reset_img_properties(raw_stack_cropped)
					raw_stack_cropped = subset_planes(raw_stack_cropped, planes_kept)
					fs = FileSaver(raw_stack_cropped)
					fs.saveAsTiff(os.path.join(raw_cropped_dir, os.path.split(raw_stack_file_name)[1]))


def get_raw_images_dir(datasets_dir, dataset_id):
	dirs = [name for name in os.listdir(
		datasets_dir) if os.path.isdir(os.path.join(datasets_dir, name))]

	this_dataset_dir = fnmatch.filter(dirs, "DS%04d*" % dataset_id)
	if len(this_dataset_dir) > 1:
		error_msg = "	Error: there are multiple directories for the dataset with ID: %04d." % dataset_id
		logging.info(error_msg)
		print(error_msg)
		return None
	if len(this_dataset_dir) == 0:
		error_msg = "	Error: there are no directories for the dataset with ID: %04d." % dataset_id
		logging.info(error_msg)
		print(error_msg)
		return None
	raw_images_dir = os.path.join(
		datasets_dir, this_dataset_dir[0], RAW_IMAGES_DIR_NAME)
	if not os.path.isdir(raw_images_dir):
		error_msg = "	Error: there are no %s directoriy for the dataset with ID: %04d." % (RAW_IMAGES_DIR_NAME, dataset_id)
		logging.info(error_msg)
		print(error_msg)
		return None
	return raw_images_dir


def make_directions_dirs(input_dir):
	direction_dirs = []
	for i in range(1, 5):
			new_dir = os.path.join(input_dir, "DR" + str(i).zfill(4))
			direction_dirs.append(new_dir)
			if not os.path.exists(new_dir):
				mkpath(new_dir)
				
	return direction_dirs
		

def get_tiff_name_from_dir(input_dir):
	file_name = None
	for fname in os.listdir(input_dir):
		if fname.lower().endswith(".tif"):
			file_name = fname
		break
	if file_name == None:
		raise Exception("Did not find any TIFF files in a directory: %s" % input_dir)

	file_name = FredericFile(file_name)
	return file_name


def move_files(raw_images_dir, specimen_directions_in_channels, dataset_id, dataset_name_prefix):
	"""Splits the embryo images by direction and puts in separate channel/direction folders. 
	Renames the files to conform to FredericFile format.

	Args:
		raw_images_dir (str): full path to mixed raw images files
		specimens_per_direction ( ((4,3,2,1),(5,6,8,7)) ): a tuple, each element has info for a channel with this index. 
		Info is a tuple with correspondance speciment number and directions, where directions are corresponding index in the tuple.
		dataset_id (int): ID number of the dataset
		dataset_name_prefix (str): prefix that the user specifies for the dataset

	Raises:
		Exception: metadata does not contain the specimen extracted from the file names
	"""
	specimens_info = {}
	for channel, directions in enumerate(specimen_directions_in_channels, start=1):
		chan_dir = os.path.join(raw_images_dir, "CH%04d" % channel)
		if not os.path.exists(chan_dir):
			os.mkdir(chan_dir)
		direction_dirs = make_directions_dirs(chan_dir)
		for direct, specimen in enumerate(directions, start=1):
			specimens_info[specimen] = {"channel": channel, "direction": direct}

	for file_name in os.listdir(raw_images_dir):
		file_path = os.path.join(raw_images_dir, file_name)

		if os.path.isdir(file_path):
			continue
		if not file_name.endswith((".tif", ".TIF")):
			continue

		specimen = int(
			file_name[file_name.find("SPC0") + 4: file_name.find("SPC0") + 6])
		time_point = int(
			file_name[file_name.find("TL") + 2: file_name.find("TL") + 6]) + 1
		# channel = int(file_name[file_name.find("CHN") + 3: file_name.find("TL") + 5]) + 1 # Not used for old mDSLM images

		if specimen not in specimens_info:
			raise ValueError("In the metadata for the dataset: DS %04d there is no entry for the specimen: %i" % (
				dataset_id, specimen))


		image_channel = specimens_info[specimen]["channel"]
		embryo_direction = specimens_info[specimen]["direction"]
		new_file_name = "%sDS%04dTP%04dDR%04dCH%04dPL(ZS).tif" % (dataset_name_prefix,
																  dataset_id,
																  time_point,
																  embryo_direction,
                                                            	  image_channel)
		os.rename(file_path, os.path.join(
			direction_dirs[embryo_direction - 1], new_file_name))
		logging.info("New file \n%s\n Full path:\n%s\n Original name: \n%s\n Original path: \n%s\n" % (new_file_name,
																									   os.path.join(
																										   direction_dirs[embryo_direction - 1], new_file_name),
																									   file_name,
																									   file_path)
					 )


def is_specimen_input_valid(specimens_per_direction):
	if not isinstance(specimens_per_direction, tuple):
		return False
	possible_specimens_lists = [[0, 1, 2, 3], [4, 5, 6, 7], [8,9,10,11], [12,13,14,15], [16,17,18,19], [20,21,22,23]]
	if sorted(list(specimens_per_direction)) in possible_specimens_lists:
		return True
	return False


def is_dataset_ID_input_valid(dataset_id):
	if not isinstance(dataset_id, int):
		return False
	if dataset_id in range(10000):
		return True
	return False


def get_tiffs_in_directory(directory):
	"""Get all TIFF file paths in a directory. Subdirectories are not searched.

	Args:
		directory (str): full path to directory

	Raises:
		Exception: If no images were found

	Returns:
		str[]: list of full paths to tiff files
	"""
	file_names = []
	for fname in os.listdir(directory):
		if fname.lower().endswith(".tif"):
			file_names.append(os.path.join(directory, fname))
	file_names = sorted(file_names)
	if len(file_names) < 1:
		raise Exception("No image files found in %s" % directory)	
	return file_names


def project_a_stack(stack):
	"""Project a stack of images along the Z axis 

	Args:
		stack ImagePlus: stack of images to project

	Returns:
		ImagePlus: max-projection
	"""
	zp = ZProjector(stack)
	zp.setMethod(ZProjector.MAX_METHOD)
	zp.doProjection()
	zpimp = zp.getProjection()
	return zpimp


def make_max_Z_projections_for_folder(input_dir, output_dir):
	"""Takes all stacks from a directory, does their max-projection, makes a stack of max-projections, saves it to output directory and returns it. 

	Args:
		input_dir (string): path to stacks of images (has to be images from ImagePlus objects)
		output_dir (string): path to output folder

	Returns:
		ImagePlus: stack of max-projections
	"""
	fnames = get_tiffs_in_directory(input_dir)
	# Open and stack images
	img_for_dims = IJ.openImage(fnames[0])
	stack_list = []
	for fname in fnames:
		stack = IJ.openImage(fname)
		# Select which dimension to project
		max_proj = project_a_stack(stack)
		stack_list.append(max_proj.getProcessor())
	tstack_name = FredericFile(os.path.split(fnames[0])[1])
	tstack_name.time_point = "(TS)"
	tstack_name.plane = "(ZM)"
	max_proj_stack = ImageStack(img_for_dims.width, img_for_dims.height)
	for slice in stack_list:
		max_proj_stack.addSlice(None, slice)
	max_proj_stack = ImagePlus("max_proj", max_proj_stack)
	max_proj_stack = reset_img_properties(max_proj_stack)
	fs = FileSaver(max_proj_stack)
	fs.saveAsTiff( os.path.join(output_dir, tstack_name.get_name()))
	return max_proj_stack


def create_crop_template(max_time_projection, meta_dir, dataset):
	"""Crop max_time_projection, create crop template .roi object, save it in meta_dir.

	Args:
		max_time_projection (ImagePlus): a single image of max projection of a time stack of max projections
		meta_dir (str): full path to metadata dir
		dataset (dict): metadata about the dataset to extract information about embryo orientation

	Returns:
		crop_template (Roi): bounding box around the embryo with proper rotation and size
		cropped_max_time_proj (ImagePlus): cropped max time projection
	"""
	IJ.run("Clear Results")

	imp = max_time_projection
	ip = imp.getProcessor().duplicate()  # get pixel array?, as a copy

	imp2 = ImagePlus("mask", ip)
	radius = 4
	RankFilters().rank(ip, radius, RankFilters.MEDIAN)

	hist = ip.getHistogram()
	triag_threshold = Auto_Threshold.Triangle(hist)
	ip.setThreshold(triag_threshold, float("inf"), ImageProcessor.NO_LUT_UPDATE)
	IJ.run(imp2, "Convert to Mask", "")
	table = ResultsTable()
	roim = RoiManager(False)  # Initialise without display (boolean value is ignored)
	MIN_PARTICLE_SIZE = 10000  # pixel ^ 2
	MAX_PARTICLE_SIZE = float("inf")
	ParticleAnalyzer.setRoiManager(roim)
	pa = ParticleAnalyzer(
            ParticleAnalyzer.ADD_TO_MANAGER,
            Measurements.ELLIPSE,
            table,
            MIN_PARTICLE_SIZE,
            MAX_PARTICLE_SIZE
        )
	pa.analyze(imp2)
	rot_angle = round(table.getValue("Angle", 0))
	roi_arr = roim.getRoisAsArray()
	roim.runCommand('reset')
	imp.setRoi(roi_arr[len(roi_arr) - 1])
	IJ.run(imp, "Select Bounding Box (guess background color)", "")
	bounding_roi = imp.getRoi()
	bounding_center_x = bounding_roi.getContourCentroid()[0]
	bounding_center_y = bounding_roi.getContourCentroid()[1]
	IJ.run(imp, "Specify...", "width=1050 height=600 x=%s y=%s centered" %
	       (bounding_center_x, bounding_center_y))
	roim.runCommand('reset')
	bounding_roi = imp.getRoi()
	bounding_roi_rot = RoiRotator.rotate(bounding_roi, -rot_angle)
	imp.setRoi(bounding_roi_rot, True)
	crop_template = imp.getRoi()
	roim.addRoi(crop_template)
	roim.select(0)
	roim.runCommand("Save", os.path.join(meta_dir, "crop_template.roi"))
	final_imp = imp.crop() # This crops by a unrotated bounding box created around the rotated selection box
						   # so later, when we rotate and crop again there will be no blacked corners in the image.
	IJ.run(final_imp, "Select All", "")
	IJ.run(final_imp, "Rotate... ",
	       "angle=%s grid=1 interpolation=Bilinear" % rot_angle)
	final_center_x = final_imp.getWidth() / 2
	final_center_y = final_imp.getHeight() / 2
	IJ.run(final_imp, "Specify...", "width=1050 height=600 x=%s y=%s centered" %
            (final_center_x, final_center_y))
	cropped_max_time_proj = final_imp.crop()
	if dataset["head_direction"] == "left":
		IJ.run(cropped_max_time_proj, "Rotate 90 Degrees Right", "")

		# So that illumination is comming from the right. 
		# Right now everything is based on that illumination on the images from mDSLM is always coming from the top.
		IJ.run(cropped_max_time_proj, "Flip Horizontally", "") 
	else:
		IJ.run(cropped_max_time_proj, "Rotate 90 Degrees Left", "")
	roim.close()
	table.reset()
	return (crop_template, cropped_max_time_proj)


def get_polygon_roi_angle(roi):
	"""Returns an angle between first line in the PolygonRoi and horizontal line

	Args:
		roi (PolygonRoi): intended for rectangular Rois

	Returns:
		double: angle between first line in the PolygonRoi and horizontal line
	"""
	x1 = roi.getPolygon().xpoints[0]
	x2 = roi.getPolygon().xpoints[1]
	y1 = roi.getPolygon().ypoints[0]
	y2 = roi.getPolygon().ypoints[1]
	angle = roi.getAngle(x1, y1, x2, y2)
	return angle


def crop_stack_by_template(stack, crop_template, dataset):
	"""Crop stack by provided PolygonRoi which should be a rotated rectangle around the embryo.
	It also flips the ebryo accroding to metadata about embryo facing direction, so that illumination is from the left.

	Args:
		stack (ImagePlus): a stack of image planes
		crop_template (PolygonRoi): rotated bounding rectangle around the embryo
		dataset (dict): metadata about the dataset to extract information about embryo orientation

	Returns:
		ImagePlus: cropped stack
	"""

	stack.setRoi(crop_template)
	cropped_stack = stack.crop("stack")
	stack = None
	# cropped_stack.show()
	IJ.run(cropped_stack, "Select All", "")

	IJ.run(cropped_stack, "Rotate... ",
		"angle=%s grid=1 interpolation=Bilinear stack" % int(round(get_polygon_roi_angle(crop_template))))
	final_center_x = cropped_stack.getWidth() / 2
	final_center_y = cropped_stack.getHeight() / 2
	IJ.run(cropped_stack, "Specify...", "width=1050 height=600 x=%s y=%s centered" %
	       (final_center_x, final_center_y))
	cropped_stack_resized = cropped_stack.crop("stack")

	if dataset["head_direction"] == "left":
		IJ.run(cropped_stack_resized, "Rotate 90 Degrees Right", "")
		IJ.run(cropped_stack_resized, "Flip Horizontally", "stack")
	else:
		IJ.run(cropped_stack_resized, "Rotate 90 Degrees Left", "")
	return cropped_stack_resized


def find_planes_to_keep(zstack, meta_dir):
	"""Calculates planes to keep, so that the embryo is centered in them. 
	Saves a cropped Y_projected stack for user assessment in the metadata directory. 

	Args:
		zstack (ImagePlus): cropped Z-stack
		meta_dir (str): absolute path to metadata directory to save the Y-max projection of the image for the user to asses the plane selection 

	Returns:
		(int, int): (start_plane, stop_plane) ends have to be included.
	"""
	IJ.run(zstack, "Properties...",
            "pixel_width=1.0000 pixel_height=1.0000 voxel_depth=4.0000")

	# This variant of implementation does not recalculate the pixel values and does not expand the image.
	# So later, when we convert to mask, the image will be number_of_planes in height, and not 4*number_of_planes
	# as would be with the Reslice made from GUI.
	# This does not account for voxel_depth, so the resliced image is not rectangular.
	for_user_asessment = zstack.duplicate()
	resliced = Slicer.reslice(Slicer(), zstack)

	max_proj_reslice = project_a_stack(resliced)
	ip = max_proj_reslice.getProcessor()
	radius = 4
	RankFilters().rank(ip, radius, RankFilters.MEDIAN)

	hist = ip.getHistogram()
	triag_threshold = Auto_Threshold.Mean(hist)
	ip.setThreshold(triag_threshold, float("inf"), ImageProcessor.NO_LUT_UPDATE)
	IJ.run(max_proj_reslice, "Convert to Mask", "")

	table = ResultsTable()
	# Initialise RoiManager without display (boolean value is ignored)
	roim = RoiManager(False)
	MIN_PARTICLE_SIZE = 2000  # pixel ^ 2
	MAX_PARTICLE_SIZE = float("inf")
	ParticleAnalyzer.setRoiManager(roim)
	pa = ParticleAnalyzer(
            ParticleAnalyzer.ADD_TO_MANAGER,
            Measurements.RECT,
            table,
            MIN_PARTICLE_SIZE,
            MAX_PARTICLE_SIZE
        )
	pa.analyze(max_proj_reslice)
	box_start = table.getValue("BY", 0)
	box_width = table.getValue("Height", 0)
	middle_y = box_start + box_width / 2
	start_plane = int(round(middle_y - 75))
	end_plane = int(round(middle_y + 74))

	# Save cropped Y-projection for user assessment
	for_user_asessment = subset_planes(
		for_user_asessment, (start_plane, end_plane))

	#TODO: Find how to make this headless
	IJ.run(for_user_asessment, "Reslice [/]...", "output=1 start=Top")
	for_user_asessment = WindowManager.getCurrentImage()
	for_user_asessment.hide()

	for_user_asessment = project_a_stack(for_user_asessment)
	fs = FileSaver(for_user_asessment)
	fs.saveAsTiff(os.path.join(meta_dir, "Y_projected_raw_stack_for_asessment_of_plane_selection.tif"))


	return (start_plane, end_plane)
	

def reset_img_properties(image):
	"""Reset properties for an ImagePlus image and remove slice lables

	Args:
		image (ImagePlus): input image

	Returns:
		ImagePlus: image with reset properties
	"""
	depth = 4
	nslices = image.getNSlices()
	if nslices == 1:
		depth = 1
	IJ.run(image, "Properties...", "channels=1 slices=%s frames=1 unit=pixel pixel_width=1.0000 pixel_height=1.0000 voxel_depth=%s.0000 origin=0,0,0" % (nslices, depth))

	# Equivalent of "Remove Slice Labels" I had to do it manually because
	# "Remove Slice Labels" function always displays the output image
	stack = image.getStack()
	size = image.getStackSize()
	for i in range(1, size + 1):
		stack.setSliceLabel(None, i)
	if size == 1:
		image.setProperty("Label", None)

	return image


def subset_planes(stack_img, planes):
	"""Leave only specified planes in zstack

	Args:
		zstack (ImagePlus): stack to crop
		planes (int, int): (start_plane, end_plane) ends included in the output stack

	Returns:
		ImagePlus: cropped stack
	"""
	# I had to do it manually because the built in function (Keep slices) always displays the image
	stack = stack_img.getStack()
	cropped_stack = ImageStack(stack.getWidth(), stack.getHeight())
	for i in range(planes[0], planes[1] + 1):
		ip = stack.getProcessor(i)
		cropped_stack.addSlice(ip)
	stack_img.setStack(cropped_stack)
	return stack_img


def auto_contrast(image):
	ip = image.getProcessor()
	hist = ip.getHistogram()
	triag_threshold = Auto_Threshold.Triangle(hist)
	num_overexposed_pixels = 0
	upper_threshold = 10000
	for i, num_pixels_with_this_value in reversed(list(enumerate(hist))):
		num_overexposed_pixels += num_pixels_with_this_value
		if num_overexposed_pixels > 100:
			upper_threshold = i
			break
	image.setDisplayRange(triag_threshold, upper_threshold)
	IJ.run(image, "Apply LUT", "")
	return image

if __name__ in ['__builtin__', '__main__']:
	process_datasets(datasets_dir, metadata_file, dataset_name_prefix)
